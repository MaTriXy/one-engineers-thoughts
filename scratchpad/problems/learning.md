
Is learning just problem solving? When you don't know something, you have a problem. Then look for the answer on google.

If you see something you have no idea about, you at least have the _context_ you found the thing in. Then you search within the space of that context, such as the whole field of computer science, and try to find something that seems similar. Once you see something that looks similar, you make the conclusion ("propose the solution") that those two things are in fact the same thing. Then you look for evidence by searching "ps command", or "is x a type of y". If you find further evidence that that thing is actually that type of thing, then your solution is valid. This is how you gather knowledge / learn.

If there isn't existing knowledge already out there, then you have to experiment. Propose hypotheses, then run experiments.

- machine learning through hypothesis generation

As you learn the types of things, their functions, attributes, and relations, then you can ask better questions. So it's a sort of cycle of refinement and deeper learning.

Apple -> types of apples -> apple is fruit, orange is fruit, therefore there must be different types of oranges:

Question: What types of oranges are there?

As questions become refined, they solve clearer problems, and you learn what resources are good to learn from and what are not. You develop heuristics to filter out bad search results, and ask better questions. And look for patterns. Question: Are there any patterns in this set of characters?

A good way to learn new things is to find relations/metaphors to things you already know, find patterns, and ask questions.

When you get answers / solutions validated, those become good questions to ask. That is, they are solutions to problems that worked in the past.

The origin of consciousness may have been at the boundary between a function and problem solving. For problem solving, you need a _desire_ to transform to a different state. To have a desire, you just need to _know_ that there is an alternative state. So it's like, you just need a memory, and the ability to recall that memory to change your actions. Once you can do that, then you are problem solving. This is a testable hypothesis!

We think of trees as not problem solving, because they don't have the memory so they can intentionally change their state. Instead, they are reactive. They have _functions_, which could transform them (such as move them more into the light), but this isn't problem solving.

A function that slowly remembers how to change state from one to another.

In order to problem solve, it seems you need a memory. So, maybe trees do record the input/output of functions, and use that information in future actions. But maybe it is so slow to change their action, that we don't notice it. So then maybe our idea of consciousness only is for things where we can _see_ then do something on purpose. A tree may do something on purpose, but it is so slow or subtle we don't notice.

http://www.rif.org/us/literacy-resources/articles/literacy-milestones-from-birth-to-age-six.htm

An answer's usefulness is how well it fits with your existing model. Maybe some new perspective, tho, completely changes how you interpret everything in your new model. If it's a very simple pattern, and there is a way to reshape your existing model to more simplify fit the new pattern, then that's how that works.

Maybe conscious is sort of metacognition. It knows that it can solve problems, so it intentionally solves it. Picks it out of its memory and solves it.

Perception and action. Input, output.

Percept = input
artifact = output

You observe and get input percepts, and evaluate them against your design and all criteria to see if you have transformed the old current state into the desired state.

http://www.cs.umd.edu/projects/active/publications/papers/cox_et_al_11.pdf

- explantation == reason
- "explanatory hypothesis"
- "theory of explanation"
- are solutions == plans? plans are the actions you think you take to get to a goal. proposed solutions are plans? _action_ is actually performing the plans
- _feedback_ looking to see if goal was achieved, and if not, the reasons why not. so evaluating a solution was found, and if not why not.
- "case base" - compendium of past solutions to problems in a certain application domain
  + source case (existing case)
  + target case (new case)
- Experience items (called cases) capture solu- tions to previous problems and are collected and stored in a case base, i.e., a repository of successful problem solving episodes. 
- contextualized preferences
- > In our Pref-CBR framework, case-based problem solving is formalized as
a preference-guided search process in the space of candidate solutions,
which is equipped with a similarity (or, equivalently, a distance) measure.
- Fuzzy rule-based reasoning
- precedent: previous case used for guidance
- case: several features describing a problem, plus an outcome or a solution
  - they can be very rich
  - they are not distilled knowledge
  - they are records of real events
  - they are excellent for justifying decisions
- distance to nearest neighbor is calculated
  - this suggests a precedent: the loan will be successful
  - problem space
  - feature vectors
  - "nearest neighbor retrieval"
- precedent is an accepted method for justifying a decision.
  + neural nets and genetic algorithms cannot be used to justify their decisions
  + rule based systems are unintuitive
