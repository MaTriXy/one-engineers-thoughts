
> analogy or isomorphism between propositions and types

The formal theory works with types and objects.

A type is declared by:

A\ \mathsf{Type}
An object exists and is in a type if:

a \mathbin{:} A

> HoTT uses a modified version of the Propositions as Types interpretation of type theory, according to which types can also represent propositions and terms can then represent proofs

A type system is a system of symbols. A system of information structures represented in cognition.

http://en.wikipedia.org/wiki/Category_theory

> By studying categories and functors, we are not just studying a class of mathematical structures and the morphisms between them; we are studying the relationships between various classes of mathematical structures.

http://en.wikipedia.org/wiki/Category_theory

> Functors and natural transformations ('naturality') are the key concepts in category theory.

> A category C consists of two classes, one of objects and the other of morphisms.

It's like saying a type consists of information structures and their relations.

Morphisms are like changes.

> Relations among morphisms (such as fg = h) are often depicted using commutative diagrams.

There it is again, "relation" being used to describe the thing. A morphism _is_ a relation.

A type is like a name a cognitive agent uses to store and retrieve information structures.

That's why just "naming a type" is "proof of it's existence" (constructivist mathematics). It is because it is just a label for an information structure stored in an agent. The problem then is, how to make these symbols all _logically consistent_.

Consistency, however, is probably not a necessary thing. It is just a quality of a good system, because it means that we can model everything as a whole.

```
Information -> Observed Structure -> Storage -> Type (for reasoning efficiently and effectively).
```

Possible theorem: The most effective reasoning occurs when all types are logically consistent. This is the point of mathematics, to create a consistent model of the universe. If there are inconsistencies, you can still solve problems, you just will introduce unforseen problems and so not be as efficient.

So if we can convert our stored mental structures into a consistent, coherent type system, then we can efficiently reason and make predictions about the universe. That is the goal of this theory.

Types have a set of relations, and a set of constraints on those relations.

Dependent types are just types that depend on other types. In this sense, it is a structure of structures. So you can determine if a dependent type is a list, or a tree, or a graph, or anything else.

http://en.wikipedia.org/wiki/Pure_type_system

Paper: Natural Type Theory

http://homepages.inf.ed.ac.uk/rpollack/export/formalPTS.pdf
http://cstheory.stackexchange.com/questions/16953/constraint-types-ibm-x10-compared-to-dependent-types#

http://www.nanocow.com/nystrom/papers/generics.pdf

Constraint types
Refinement types

Structural Type Theory

A type is an abstract mental structure.

So "out there", the ontology is sorta like:

```
Information -> Structure -> Type
```

In our mind the start is:

```
Type -> Structure
Type -> Information
Type -> Type
```

It's okay that it's cyclic because it's a mental structure. A type is an information structure, and an information structure is a type abstract.

https://en.wikipedia.org/wiki/Foundations_of_mathematics

---

"Type" isn't the best word to use for recognizable information. It's too high level to stand as a base. "Types" of things are complete mental models, based on our language. Patterns, instead, are much more fundamental. They are based on the relationship between our brains and external information. They are much more low-level than language, yet can be used to model languages. So patterns serve as the base of the model, rather than types.
